{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c566726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class FeatureEngineer:\n",
    "    \"\"\"\n",
    "    Advanced feature engineering for Santander product recommendation\n",
    "    Optimized for memory efficiency\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, product_cols: List[str]):\n",
    "        self.product_cols = product_cols\n",
    "        self.categorical_cols = ['segmento', 'ind_actividad_cliente', 'canal_entrada', \n",
    "                                 'cod_prov', 'indrel_1mes', 'tiprel_1mes']\n",
    "        \n",
    "    def create_lag_features(self, df: pd.DataFrame, n_lags: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create lag features for products and categorical variables\n",
    "        Memory efficient implementation using chunks\n",
    "        \"\"\"\n",
    "        print(\"Creating lag features...\")\n",
    "        \n",
    "        # Sort by customer and date\n",
    "        df = df.sort_values(['ncodpers', 'fecha_dato'])\n",
    "        \n",
    "        # Initialize feature dict\n",
    "        lag_features = {}\n",
    "        \n",
    "        # Process in chunks to save memory\n",
    "        chunk_size = 100000\n",
    "        n_chunks = len(df) // chunk_size + 1\n",
    "        \n",
    "        for chunk_idx in range(n_chunks):\n",
    "            start_idx = chunk_idx * chunk_size\n",
    "            end_idx = min((chunk_idx + 1) * chunk_size, len(df))\n",
    "            \n",
    "            chunk = df.iloc[start_idx:end_idx]\n",
    "            \n",
    "            # Product lags\n",
    "            for lag in range(1, n_lags + 1):\n",
    "                for col in self.product_cols[:10]:  # Start with top 10 products\n",
    "                    lag_col = f'{col}_lag_{lag}'\n",
    "                    chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
    "                    \n",
    "            # Categorical lags (for changes)\n",
    "            for lag in range(1, 3):  # Only 2 lags for categorical\n",
    "                for col in self.categorical_cols:\n",
    "                    if col in df.columns:\n",
    "                        lag_col = f'{col}_lag_{lag}'\n",
    "                        chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
    "            \n",
    "            # Store results\n",
    "            if chunk_idx == 0:\n",
    "                result_df = chunk\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, chunk], axis=0)\n",
    "            \n",
    "            if chunk_idx % 10 == 0:\n",
    "                print(f\"Processed {chunk_idx}/{n_chunks} chunks\")\n",
    "                gc.collect()\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def create_time_since_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create 'time since' features for product ownership and changes\n",
    "        \"\"\"\n",
    "        print(\"Creating time since features...\")\n",
    "        \n",
    "        # Convert fecha_dato to datetime if not already\n",
    "        df['fecha_dato'] = pd.to_datetime(df['fecha_dato'])\n",
    "        \n",
    "        # Sort by customer and date\n",
    "        df = df.sort_values(['ncodpers', 'fecha_dato'])\n",
    "        \n",
    "        # For each product, calculate months since first/last ownership\n",
    "        for product in self.product_cols[:10]:  # Top 10 products\n",
    "            # Time since first ownership\n",
    "            df[f'{product}_months_since_first'] = df.groupby('ncodpers').apply(\n",
    "                lambda x: self._calculate_months_since_first(x, product)\n",
    "            ).reset_index(level=0, drop=True)\n",
    "            \n",
    "            # Time since last purchase (if changed from 0 to 1)\n",
    "            df[f'{product}_months_since_purchase'] = df.groupby('ncodpers').apply(\n",
    "                lambda x: self._calculate_months_since_purchase(x, product)\n",
    "            ).reset_index(level=0, drop=True)\n",
    "        \n",
    "        # Time since any change in categorical variables\n",
    "        for col in self.categorical_cols:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_months_since_change'] = df.groupby('ncodpers').apply(\n",
    "                    lambda x: self._calculate_months_since_change(x, col)\n",
    "                ).reset_index(level=0, drop=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_aggregation_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create aggregated features by customer segments\n",
    "        \"\"\"\n",
    "        print(\"Creating aggregation features...\")\n",
    "        \n",
    "        # Product ownership rates by segment combinations\n",
    "        segment_cols = ['segmento', 'cod_prov', 'canal_entrada']\n",
    "        \n",
    "        for seg_col in segment_cols:\n",
    "            if seg_col in df.columns:\n",
    "                # Calculate mean product ownership by segment\n",
    "                for product in self.product_cols[:5]:  # Top 5 products\n",
    "                    agg_col = f'{product}_mean_by_{seg_col}'\n",
    "                    segment_means = df.groupby(seg_col)[product].mean()\n",
    "                    df[agg_col] = df[seg_col].map(segment_means)\n",
    "        \n",
    "        # Customer-level aggregations\n",
    "        customer_aggs = df.groupby('ncodpers').agg({\n",
    "            **{col: ['mean', 'sum', 'std'] for col in self.product_cols[:5]},\n",
    "            'antiguedad': ['mean', 'max'],\n",
    "            'age': ['mean']\n",
    "        })\n",
    "        \n",
    "        # Flatten column names\n",
    "        customer_aggs.columns = ['_'.join(col).strip() for col in customer_aggs.columns.values]\n",
    "        \n",
    "        # Merge back\n",
    "        df = df.merge(customer_aggs, on='ncodpers', how='left', suffixes=('', '_customer'))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_trend_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create trend and momentum features\n",
    "        \"\"\"\n",
    "        print(\"Creating trend features...\")\n",
    "        \n",
    "        # Sort by customer and date\n",
    "        df = df.sort_values(['ncodpers', 'fecha_dato'])\n",
    "        \n",
    "        # Product count trends\n",
    "        df['total_products'] = df[self.product_cols].sum(axis=1)\n",
    "        \n",
    "        # Rolling averages\n",
    "        for window in [3, 6]:\n",
    "            df[f'total_products_ma_{window}'] = df.groupby('ncodpers')['total_products'].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).mean()\n",
    "            )\n",
    "        \n",
    "        # Product momentum (change in last 3 months)\n",
    "        df['product_momentum'] = df.groupby('ncodpers')['total_products'].diff(3)\n",
    "        \n",
    "        # Seasonal features\n",
    "        df['month'] = df['fecha_dato'].dt.month\n",
    "        df['quarter'] = df['fecha_dato'].dt.quarter\n",
    "        df['is_year_end'] = (df['month'].isin([11, 12])).astype(int)\n",
    "        df['is_quarter_end'] = (df['month'].isin([3, 6, 9, 12])).astype(int)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_target_encoding(self, df: pd.DataFrame, target_col: str = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create target encoding features for categorical variables\n",
    "        Memory efficient implementation\n",
    "        \"\"\"\n",
    "        print(\"Creating target encoding features...\")\n",
    "        \n",
    "        if target_col is None:\n",
    "            # Create a proxy target: whether customer added any product\n",
    "            df['added_product'] = 0\n",
    "            for product in self.product_cols:\n",
    "                df['added_product'] |= (df[product] > df[product].shift(1)).astype(int)\n",
    "        else:\n",
    "            df['added_product'] = df[target_col]\n",
    "        \n",
    "        # Target encode categorical variables\n",
    "        for cat_col in self.categorical_cols:\n",
    "            if cat_col in df.columns:\n",
    "                # Calculate encoding on training data\n",
    "                encoding = df.groupby(cat_col)['added_product'].mean()\n",
    "                df[f'{cat_col}_target_enc'] = df[cat_col].map(encoding)\n",
    "                \n",
    "                # Add noise to prevent overfitting\n",
    "                noise = np.random.normal(0, 0.01, len(df))\n",
    "                df[f'{cat_col}_target_enc'] += noise\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Helper methods\n",
    "    def _calculate_months_since_first(self, group, product):\n",
    "        \"\"\"Calculate months since first ownership of product\"\"\"\n",
    "        first_owned = group[group[product] == 1]['fecha_dato'].min()\n",
    "        if pd.isna(first_owned):\n",
    "            return [999] * len(group)  # Never owned\n",
    "        return [(row['fecha_dato'] - first_owned).days // 30 for _, row in group.iterrows()]\n",
    "    \n",
    "    def _calculate_months_since_purchase(self, group, product):\n",
    "        \"\"\"Calculate months since product was purchased (0->1 transition)\"\"\"\n",
    "        purchases = group[(group[product] == 1) & (group[product].shift(1) == 0)]['fecha_dato']\n",
    "        if len(purchases) == 0:\n",
    "            return [999] * len(group)\n",
    "        last_purchase = purchases.max()\n",
    "        return [(row['fecha_dato'] - last_purchase).days // 30 for _, row in group.iterrows()]\n",
    "    \n",
    "    def _calculate_months_since_change(self, group, col):\n",
    "        \"\"\"Calculate months since last change in categorical variable\"\"\"\n",
    "        changes = group[group[col] != group[col].shift(1)]['fecha_dato']\n",
    "        if len(changes) <= 1:  # No changes except first occurrence\n",
    "            return [999] * len(group)\n",
    "        last_change = changes.iloc[-1]\n",
    "        return [(row['fecha_dato'] - last_change).days // 30 for _, row in group.iterrows()]\n",
    "    \n",
    "    def engineer_all_features(self, df: pd.DataFrame, is_train: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply all feature engineering steps\n",
    "        \"\"\"\n",
    "        print(f\"Starting feature engineering on {len(df)} rows...\")\n",
    "        initial_memory = df.memory_usage(deep=True).sum() / 1024**2\n",
    "        print(f\"Initial memory usage: {initial_memory:.2f} MB\")\n",
    "        \n",
    "        # 1. Lag features\n",
    "        df = self.create_lag_features(df, n_lags=3)\n",
    "        gc.collect()\n",
    "        \n",
    "        # 2. Time since features\n",
    "        df = self.create_time_since_features(df)\n",
    "        gc.collect()\n",
    "        \n",
    "        # 3. Aggregation features\n",
    "        df = self.create_aggregation_features(df)\n",
    "        gc.collect()\n",
    "        \n",
    "        # 4. Trend features\n",
    "        df = self.create_trend_features(df)\n",
    "        gc.collect()\n",
    "        \n",
    "        # 5. Target encoding (only on train)\n",
    "        if is_train:\n",
    "            df = self.create_target_encoding(df)\n",
    "            gc.collect()\n",
    "        \n",
    "        # Optimize dtypes to save memory\n",
    "        df = self.optimize_dtypes(df)\n",
    "        \n",
    "        final_memory = df.memory_usage(deep=True).sum() / 1024**2\n",
    "        print(f\"Final memory usage: {final_memory:.2f} MB\")\n",
    "        print(f\"Total features: {len(df.columns)}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def optimize_dtypes(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Optimize data types to reduce memory usage\n",
    "        \"\"\"\n",
    "        for col in df.columns:\n",
    "            col_type = df[col].dtype\n",
    "            \n",
    "            # Skip object and datetime columns\n",
    "            if col_type == 'object' or pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "                continue\n",
    "            \n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            # Skip if NaN values make min/max invalid\n",
    "            if pd.isna(c_min) or pd.isna(c_max):\n",
    "                continue\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "            elif str(col_type)[:5] == 'float':\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fafd590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/3325058399.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv('/Users/dennis_m_jose/Documents/GitHub/Santander-RecSys-Dennis/data/cleaned_santander_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature engineering on 50000 rows...\n",
      "Initial memory usage: 49.66 MB\n",
      "Creating lag features...\n",
      "Processed 0/1 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n",
      "/var/folders/jl/5_rcdjz121v7rnhqrmsz6df80000gn/T/ipykernel_10913/1346384370.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[lag_col] = chunk.groupby('ncodpers')[col].shift(lag)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating time since features...\n",
      "Creating aggregation features...\n",
      "Creating trend features...\n",
      "Creating target encoding features...\n",
      "Final memory usage: 138.47 MB\n",
      "Total features: 162\n",
      "Original columns: 46\n",
      "Featured columns: 162\n",
      "New features created: 116\n",
      "\n",
      "Sample of new features created:\n",
      "['ind_ahor_fin_ult1_lag_1', 'ind_aval_fin_ult1_lag_1', 'ind_cco_fin_ult1_lag_1', 'ind_cder_fin_ult1_lag_1', 'ind_cno_fin_ult1_lag_1', 'ind_ctju_fin_ult1_lag_1', 'ind_ctma_fin_ult1_lag_1', 'ind_ctop_fin_ult1_lag_1', 'ind_ctpp_fin_ult1_lag_1', 'ind_deco_fin_ult1_lag_1']\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned data\n",
    "df_train = pd.read_csv('/Users/dennis_m_jose/Documents/GitHub/Santander-RecSys-Dennis/data/cleaned_santander_data.csv')\n",
    "product_cols = [col for col in df_train.columns if col.endswith('ult1')]\n",
    "\n",
    "# Initialize feature engineer\n",
    "fe = FeatureEngineer(product_cols)\n",
    "\n",
    "# Testing on small sample first to avoid long runtimes\n",
    "sample_df = df_train.head(50000).copy()\n",
    "featured_sample = fe.engineer_all_features(sample_df, is_train=True)\n",
    "\n",
    "print(f\"Original columns: {len(sample_df.columns)}\")\n",
    "print(f\"Featured columns: {len(featured_sample.columns)}\")\n",
    "print(f\"New features created: {len(featured_sample.columns) - len(sample_df.columns)}\")\n",
    "\n",
    "#few of the new features\n",
    "new_features = [col for col in featured_sample.columns if col not in sample_df.columns]\n",
    "print(f\"\\nSample of new features created:\")\n",
    "print(new_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7eb28b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ind_ahor_fin_ult1_lag_1',\n",
       " 'ind_aval_fin_ult1_lag_1',\n",
       " 'ind_cco_fin_ult1_lag_1',\n",
       " 'ind_cder_fin_ult1_lag_1',\n",
       " 'ind_cno_fin_ult1_lag_1',\n",
       " 'ind_ctju_fin_ult1_lag_1',\n",
       " 'ind_ctma_fin_ult1_lag_1',\n",
       " 'ind_ctop_fin_ult1_lag_1',\n",
       " 'ind_ctpp_fin_ult1_lag_1',\n",
       " 'ind_deco_fin_ult1_lag_1',\n",
       " 'ind_ahor_fin_ult1_lag_2',\n",
       " 'ind_aval_fin_ult1_lag_2',\n",
       " 'ind_cco_fin_ult1_lag_2',\n",
       " 'ind_cder_fin_ult1_lag_2',\n",
       " 'ind_cno_fin_ult1_lag_2',\n",
       " 'ind_ctju_fin_ult1_lag_2',\n",
       " 'ind_ctma_fin_ult1_lag_2',\n",
       " 'ind_ctop_fin_ult1_lag_2',\n",
       " 'ind_ctpp_fin_ult1_lag_2',\n",
       " 'ind_deco_fin_ult1_lag_2',\n",
       " 'ind_ahor_fin_ult1_lag_3',\n",
       " 'ind_aval_fin_ult1_lag_3',\n",
       " 'ind_cco_fin_ult1_lag_3',\n",
       " 'ind_cder_fin_ult1_lag_3',\n",
       " 'ind_cno_fin_ult1_lag_3',\n",
       " 'ind_ctju_fin_ult1_lag_3',\n",
       " 'ind_ctma_fin_ult1_lag_3',\n",
       " 'ind_ctop_fin_ult1_lag_3',\n",
       " 'ind_ctpp_fin_ult1_lag_3',\n",
       " 'ind_deco_fin_ult1_lag_3',\n",
       " 'segmento_lag_1',\n",
       " 'ind_actividad_cliente_lag_1',\n",
       " 'canal_entrada_lag_1',\n",
       " 'cod_prov_lag_1',\n",
       " 'indrel_1mes_lag_1',\n",
       " 'tiprel_1mes_lag_1',\n",
       " 'segmento_lag_2',\n",
       " 'ind_actividad_cliente_lag_2',\n",
       " 'canal_entrada_lag_2',\n",
       " 'cod_prov_lag_2',\n",
       " 'indrel_1mes_lag_2',\n",
       " 'tiprel_1mes_lag_2',\n",
       " 'ind_ahor_fin_ult1_months_since_first',\n",
       " 'ind_ahor_fin_ult1_months_since_purchase',\n",
       " 'ind_aval_fin_ult1_months_since_first',\n",
       " 'ind_aval_fin_ult1_months_since_purchase',\n",
       " 'ind_cco_fin_ult1_months_since_first',\n",
       " 'ind_cco_fin_ult1_months_since_purchase',\n",
       " 'ind_cder_fin_ult1_months_since_first',\n",
       " 'ind_cder_fin_ult1_months_since_purchase',\n",
       " 'ind_cno_fin_ult1_months_since_first',\n",
       " 'ind_cno_fin_ult1_months_since_purchase',\n",
       " 'ind_ctju_fin_ult1_months_since_first',\n",
       " 'ind_ctju_fin_ult1_months_since_purchase',\n",
       " 'ind_ctma_fin_ult1_months_since_first',\n",
       " 'ind_ctma_fin_ult1_months_since_purchase',\n",
       " 'ind_ctop_fin_ult1_months_since_first',\n",
       " 'ind_ctop_fin_ult1_months_since_purchase',\n",
       " 'ind_ctpp_fin_ult1_months_since_first',\n",
       " 'ind_ctpp_fin_ult1_months_since_purchase',\n",
       " 'ind_deco_fin_ult1_months_since_first',\n",
       " 'ind_deco_fin_ult1_months_since_purchase',\n",
       " 'segmento_months_since_change',\n",
       " 'ind_actividad_cliente_months_since_change',\n",
       " 'canal_entrada_months_since_change',\n",
       " 'cod_prov_months_since_change',\n",
       " 'indrel_1mes_months_since_change',\n",
       " 'tiprel_1mes_months_since_change',\n",
       " 'ind_ahor_fin_ult1_mean_by_segmento',\n",
       " 'ind_aval_fin_ult1_mean_by_segmento',\n",
       " 'ind_cco_fin_ult1_mean_by_segmento',\n",
       " 'ind_cder_fin_ult1_mean_by_segmento',\n",
       " 'ind_cno_fin_ult1_mean_by_segmento',\n",
       " 'ind_ahor_fin_ult1_mean_by_cod_prov',\n",
       " 'ind_aval_fin_ult1_mean_by_cod_prov',\n",
       " 'ind_cco_fin_ult1_mean_by_cod_prov',\n",
       " 'ind_cder_fin_ult1_mean_by_cod_prov',\n",
       " 'ind_cno_fin_ult1_mean_by_cod_prov',\n",
       " 'ind_ahor_fin_ult1_mean_by_canal_entrada',\n",
       " 'ind_aval_fin_ult1_mean_by_canal_entrada',\n",
       " 'ind_cco_fin_ult1_mean_by_canal_entrada',\n",
       " 'ind_cder_fin_ult1_mean_by_canal_entrada',\n",
       " 'ind_cno_fin_ult1_mean_by_canal_entrada',\n",
       " 'ind_ahor_fin_ult1_mean',\n",
       " 'ind_ahor_fin_ult1_sum',\n",
       " 'ind_ahor_fin_ult1_std',\n",
       " 'ind_aval_fin_ult1_mean',\n",
       " 'ind_aval_fin_ult1_sum',\n",
       " 'ind_aval_fin_ult1_std',\n",
       " 'ind_cco_fin_ult1_mean',\n",
       " 'ind_cco_fin_ult1_sum',\n",
       " 'ind_cco_fin_ult1_std',\n",
       " 'ind_cder_fin_ult1_mean',\n",
       " 'ind_cder_fin_ult1_sum',\n",
       " 'ind_cder_fin_ult1_std',\n",
       " 'ind_cno_fin_ult1_mean',\n",
       " 'ind_cno_fin_ult1_sum',\n",
       " 'ind_cno_fin_ult1_std',\n",
       " 'antiguedad_mean',\n",
       " 'antiguedad_max',\n",
       " 'age_mean',\n",
       " 'total_products',\n",
       " 'total_products_ma_3',\n",
       " 'total_products_ma_6',\n",
       " 'product_momentum',\n",
       " 'month',\n",
       " 'quarter',\n",
       " 'is_year_end',\n",
       " 'is_quarter_end',\n",
       " 'added_product',\n",
       " 'segmento_target_enc',\n",
       " 'ind_actividad_cliente_target_enc',\n",
       " 'canal_entrada_target_enc',\n",
       " 'cod_prov_target_enc',\n",
       " 'indrel_1mes_target_enc',\n",
       " 'tiprel_1mes_target_enc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afffe64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>fecha_alta</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>indrel</th>\n",
       "      <th>...</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_year_end</th>\n",
       "      <th>is_quarter_end</th>\n",
       "      <th>added_product</th>\n",
       "      <th>segmento_target_enc</th>\n",
       "      <th>ind_actividad_cliente_target_enc</th>\n",
       "      <th>canal_entrada_target_enc</th>\n",
       "      <th>cod_prov_target_enc</th>\n",
       "      <th>indrel_1mes_target_enc</th>\n",
       "      <th>tiprel_1mes_target_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1013024</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2012-04-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569336</td>\n",
       "      <td>0.413330</td>\n",
       "      <td>0.674805</td>\n",
       "      <td>0.185303</td>\n",
       "      <td>0.208252</td>\n",
       "      <td>0.454834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1013031</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2012-04-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555664</td>\n",
       "      <td>0.428223</td>\n",
       "      <td>0.668457</td>\n",
       "      <td>0.488525</td>\n",
       "      <td>0.197632</td>\n",
       "      <td>0.457031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1013035</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2012-04-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550781</td>\n",
       "      <td>0.414551</td>\n",
       "      <td>0.657227</td>\n",
       "      <td>0.227905</td>\n",
       "      <td>0.209839</td>\n",
       "      <td>0.428467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1013036</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2012-04-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541992</td>\n",
       "      <td>0.418701</td>\n",
       "      <td>0.675293</td>\n",
       "      <td>0.411133</td>\n",
       "      <td>0.203491</td>\n",
       "      <td>0.451660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1013038</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2012-04-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554199</td>\n",
       "      <td>0.066772</td>\n",
       "      <td>0.682129</td>\n",
       "      <td>0.432129</td>\n",
       "      <td>0.199097</td>\n",
       "      <td>0.461914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1125272</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2013-03-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.565430</td>\n",
       "      <td>0.397949</td>\n",
       "      <td>0.670410</td>\n",
       "      <td>0.234619</td>\n",
       "      <td>0.214844</td>\n",
       "      <td>0.463135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1125274</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2013-03-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.059448</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>0.200195</td>\n",
       "      <td>0.063538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1125278</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2013-03-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543945</td>\n",
       "      <td>0.395996</td>\n",
       "      <td>0.673340</td>\n",
       "      <td>0.307617</td>\n",
       "      <td>0.207764</td>\n",
       "      <td>0.447754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1125282</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2013-03-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563965</td>\n",
       "      <td>0.422363</td>\n",
       "      <td>0.668945</td>\n",
       "      <td>0.582031</td>\n",
       "      <td>0.209473</td>\n",
       "      <td>0.468018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1375586</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.558105</td>\n",
       "      <td>0.418213</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.155029</td>\n",
       "      <td>0.216187</td>\n",
       "      <td>0.473633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows  162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fecha_dato  ncodpers ind_empleado pais_residencia sexo   age  \\\n",
       "0     2015-01-28   1013024            N              ES    H  23.0   \n",
       "1     2015-01-28   1013031            N              ES    V  40.0   \n",
       "2     2015-01-28   1013035            N              ES    V  37.0   \n",
       "3     2015-01-28   1013036            N              ES    V  66.0   \n",
       "4     2015-01-28   1013038            N              ES    V  38.0   \n",
       "...          ...       ...          ...             ...  ...   ...   \n",
       "49995 2015-01-28   1125272            N              ES    V  40.0   \n",
       "49996 2015-01-28   1125274            N              ES    V  37.0   \n",
       "49997 2015-01-28   1125278            N              ES    V  50.0   \n",
       "49998 2015-01-28   1125282            N              ES    V  44.0   \n",
       "49999 2015-01-28   1375586            N              ES    H  35.0   \n",
       "\n",
       "       fecha_alta  ind_nuevo  antiguedad  indrel  ... quarter is_year_end  \\\n",
       "0      2012-04-23        0.0          39     1.0  ...       1           0   \n",
       "1      2012-04-23        0.0          39     1.0  ...       1           0   \n",
       "2      2012-04-23        0.0          39     1.0  ...       1           0   \n",
       "3      2012-04-23        0.0          39     1.0  ...       1           0   \n",
       "4      2012-04-23        0.0          39     1.0  ...       1           0   \n",
       "...           ...        ...         ...     ...  ...     ...         ...   \n",
       "49995  2013-03-21        0.0          28     1.0  ...       1           0   \n",
       "49996  2013-03-21        0.0          28     1.0  ...       1           0   \n",
       "49997  2013-03-21        0.0          28     1.0  ...       1           0   \n",
       "49998  2013-03-21        0.0          28     1.0  ...       1           0   \n",
       "49999  2015-01-12        0.0           6     1.0  ...       1           0   \n",
       "\n",
       "      is_quarter_end added_product segmento_target_enc  \\\n",
       "0                  0             0            0.569336   \n",
       "1                  0             1            0.555664   \n",
       "2                  0             1            0.550781   \n",
       "3                  0             1            0.541992   \n",
       "4                  0             1            0.554199   \n",
       "...              ...           ...                 ...   \n",
       "49995              0             0            0.565430   \n",
       "49996              0             0            0.562500   \n",
       "49997              0             1            0.543945   \n",
       "49998              0             1            0.563965   \n",
       "49999              0             0            0.558105   \n",
       "\n",
       "      ind_actividad_cliente_target_enc  canal_entrada_target_enc  \\\n",
       "0                             0.413330                  0.674805   \n",
       "1                             0.428223                  0.668457   \n",
       "2                             0.414551                  0.657227   \n",
       "3                             0.418701                  0.675293   \n",
       "4                             0.066772                  0.682129   \n",
       "...                                ...                       ...   \n",
       "49995                         0.397949                  0.670410   \n",
       "49996                         0.059448                  0.664062   \n",
       "49997                         0.395996                  0.673340   \n",
       "49998                         0.422363                  0.668945   \n",
       "49999                         0.418213                  0.132812   \n",
       "\n",
       "       cod_prov_target_enc indrel_1mes_target_enc  tiprel_1mes_target_enc  \n",
       "0                 0.185303               0.208252                0.454834  \n",
       "1                 0.488525               0.197632                0.457031  \n",
       "2                 0.227905               0.209839                0.428467  \n",
       "3                 0.411133               0.203491                0.451660  \n",
       "4                 0.432129               0.199097                0.461914  \n",
       "...                    ...                    ...                     ...  \n",
       "49995             0.234619               0.214844                0.463135  \n",
       "49996             0.148804               0.200195                0.063538  \n",
       "49997             0.307617               0.207764                0.447754  \n",
       "49998             0.582031               0.209473                0.468018  \n",
       "49999             0.155029               0.216187                0.473633  \n",
       "\n",
       "[50000 rows x 162 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482f9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
